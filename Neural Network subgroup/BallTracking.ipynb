{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all dependencies (run as virtual environmnent)\n",
    "from collections import deque           #faster way to append arrays \n",
    "from imutils.video import VideoStream   #acces to camera\n",
    "import numpy as np \n",
    "import argparse                         #user friendly command line access \n",
    "import cv2                              #opencv for image processing\n",
    "import imutils                          #image processing tool for help with openCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = argparse.ArgumentParser()  #handles command-line arguments \n",
    "ap.add_argument('-v', '--video', help = 'path to the video (potential) file')       #set video file path\n",
    "ap.add_argument('-b', '--buffer', type=int, default=64, help = 'max buffer size')   #sets buffer size\n",
    "\n",
    "args, _ = ap.parse_known_args() #there is a discrapancy between ipynb and py this helps that\n",
    "args = vars(args)       #create a dictionary where command-line arguments can be accesed through their keys -v, --video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the lower and upper boundaries of the \"green\" ball in the HSV color space, \n",
    "# then initialize the list of tracked points\n",
    "redLower = (60, 110, 185)\n",
    "redUpper = (200, 255, 255)\n",
    "pts = deque(maxlen=args[\"buffer\"])\n",
    "\n",
    "# if a video path was not supplied, grab the reference to the webcam\n",
    "if not args.get(\"video\", False):\n",
    "\tvs = VideoStream(src=0).start()\n",
    "# otherwise, grab a reference to the video file\n",
    "else:\n",
    "\tvs = cv2.VideoCapture(args[\"video\"])\n",
    "# allow the camera or video file to warm up\n",
    "time.sleep(2.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m hsv \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(blurred, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2HSV)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# construct a mask for the color \"green\", then perform\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# a series of dilations and erosions to remove any small\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# blobs left in the mask\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minRange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhsv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredLower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredUpper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39merode(mask, \u001b[38;5;28;01mNone\u001b[39;00m, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     20\u001b[0m mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdilate(mask, \u001b[38;5;28;01mNone\u001b[39;00m, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "\t# grab the current frame\n",
    "\tframe = vs.read()\n",
    "\t# handle the frame from VideoCapture or VideoStream\n",
    "\tframe = frame[1] if args.get(\"video\", False) else frame\n",
    "\t# if we are viewing a video and we did not grab a frame,\n",
    "\t# then we have reached the end of the video\n",
    "\tif frame is None:\n",
    "\t\tbreak\n",
    "\t# resize the frame, blur it, and convert it to the HSV\n",
    "\t# color space\n",
    "\tframe = imutils.resize(frame, width=600)\n",
    "\tblurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "\thsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "\t# construct a mask for the color \"green\", then perform\n",
    "\t# a series of dilations and erosions to remove any small\n",
    "\t# blobs left in the mask\n",
    "\tmask = cv2.inRange(hsv, redLower, redUpper)\n",
    "\tmask = cv2.erode(mask, None, iterations=2)\n",
    "\tmask = cv2.dilate(mask, None, iterations=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
